{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75720aab",
   "metadata": {},
   "source": [
    "- Guillermo Benito Calviño - 2072106 \n",
    "- Claudia Lorenzetti - 2097902\n",
    "- Leon Mengoni - 2091185\n",
    "- Filippo Pra Floriani - 2089902"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9950b94",
   "metadata": {},
   "source": [
    "# BAYESIAN INFERENCE ON SOLAR DYNAMO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dbb02ae",
   "metadata": {},
   "source": [
    "Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db633ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import emcee\n",
    "import corner\n",
    "from scipy.special import erf\n",
    "from scipy.linalg import det\n",
    "from scipy.optimize import minimize\n",
    "import tqdm\n",
    "from scipy.fft import fft, ifft\n",
    "from multiprocessing import Pool\n",
    "from IPython.display import display, Math\n",
    "from julia.api import Julia\n",
    "jl = Julia(compiled_modules=False)\n",
    "from julia import Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04ce5f44",
   "metadata": {},
   "source": [
    "# Solar Dynamo Model\n",
    "\n",
    "The sun's magnetic field is generated by an inner magnetic dynamo. \n",
    "It is well known that it changes in a cyclic manner with a period of almost 11 years: the existence of such a stable period indicates that the magnetic field continues to be generated within the Sun. \n",
    "The amplitude of the oscillator is subject to a long-term modulation, including periods of very low activity, known as Grand Minima. \n",
    "It is believed that Grand Minima are induced by the tiny planetary tidal forcing.\n",
    "\n",
    "The model equation for the Solar Dynamo is:\n",
    "\n",
    "$$\n",
    "\\left(\\tau\\frac{d}{dt} + 1\\right)^2 B(t) = - \\mathcal{N}(1 + \\epsilon\\cos(\\omega_d t))f(B(t - q))B(t - q) + \\sigma B_{max} \\sqrt{\\tau} \\eta(t)\n",
    "$$\n",
    "\n",
    "\n",
    "- $B(t)$ is the magnetic field, our observable\n",
    "- $\\mathcal{N} $ is the strength of the dynamo\n",
    "- $q$ is the delay\n",
    "- $[\\sigma] = [1]$ (dimensionless) is the noise amplitude \n",
    "- $[\\tau] = [s]$ is the diffusion-time constant\n",
    "- $\\eta (t)$ is the so-called gaussian white noise\n",
    "- $T$ is the observation time\n",
    "- $\\epsilon\\cos(\\omega_d t)$ is the weak external modulation induced by a tiny planetary tidal forcing\n",
    "\n",
    "\n",
    "- Non-linear function $f(B(t))$:\n",
    "\n",
    "$$\n",
    "f(B(t)) = \\frac{1}{2} (1 + \\text{erf}(B^2 - B_{max}^2))\n",
    "$$\n",
    "\n",
    "used for constraining the B field under a certain value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "593c0db0",
   "metadata": {},
   "source": [
    "# Bayesian Inference\n",
    "\n",
    "Our scope is to find the best parameters that fit the model. \n",
    "To achieve this, we want to construct the posterior for our parameters $\\boldsymbol{\\theta} = (q, \\mathcal{N}, \\sigma, B_{max}, \\tau)$: \n",
    "\n",
    "$$\n",
    "    p(\\boldsymbol{\\theta}|B) \\propto f(B|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "given the likelihood $f(B|\\boldsymbol{\\theta})$ and our parameter prior $p(\\boldsymbol{\\theta})$, i.e. our previous knowledge. \n",
    "In this case we just require our parameters to be positive.\n",
    "\n",
    "\n",
    "In our case, instead of working with our time-dependent signal, we convert our model equation to Fourier space, and we sample the posterior in Fourier space by using a Markov Chain Monte Carlo algorithm:\n",
    "\n",
    "$$\n",
    "    p(\\boldsymbol{\\theta}|\\widehat{B}) \\propto f(\\widehat{B}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "However, instead of sampling from the distribution of $\\widehat{B}$, we want to sample from the distribution of $\\widehat{\\eta}$, because $\\eta$ is a gaussian white noise and its Fourier transform is also distributed as a gaussian.\n",
    "We therefore express $\\widehat{\\eta}$ as a function of $\\widehat{B}$.\n",
    "\n",
    "After having sampled our posterior, we obtain the best estimates through the use of a minimization algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56beecbd",
   "metadata": {},
   "source": [
    "## Model equation to Fourier space\n",
    "\n",
    "First of all we want to convert our model to the frequency domain by applying a Fourier transform. \n",
    "In this way it is possible to focus just on the frequency modes which are more interesting to be analyzed, by filtering out the negligible ones.\n",
    "\n",
    "We define the Fourier transform of our signal $B(t)$ as the $n$-th coefficient of the complex Fourier series:\n",
    "\n",
    "$$\n",
    "    \\mathcal{F}[B(t)]_n = \\widehat{B}_n = \\frac{1}{T} \\int^{T}_0 dt e^{- 2 \\pi i n \\frac{t}{T}} B(t)\n",
    "$$\n",
    "\n",
    "In order to prevent spectral-leakage, a window function will be used. In this case we will use the Hann window function:\n",
    "\n",
    "$$\n",
    "    w (t) = \\cos^2\\left(\\pi\\left(\\frac{t}{T} - \\frac{1}{2}\\right)\\right)\n",
    "$$\n",
    "\n",
    "The application of $w(t)$ to our signal helps modulate the trend of the ODE, by suppressing the function near $t = 0$ and $t = T$, whose period is forced to be exactly $T$.\n",
    "\n",
    "\n",
    "The original signal is defined as $B(t)$ and the white noise as $\\eta(t)$, while the \"windowed\" signal and the \"windowed\" noise are respectively:\n",
    "\n",
    "$$\n",
    "B^w(t) = w(t)B(t) \\hspace{1cm} \\eta^w(t) = w(t) \\eta(t)\n",
    "$$\n",
    "\n",
    "and the non-linear function has been rewritten as: \n",
    "\n",
    "$$\n",
    "    \\widetilde{f}(B(t))=f(B(t))B(t)\n",
    "$$\n",
    "\n",
    "The Fourier transform of our windowed signal is, therefore:\n",
    "\n",
    "$$\n",
    "    \\mathcal{F}[B^w(t)]_n = \\widehat{B}^w_n = \\frac{1}{T} \\int^{T}_0 dt e^{- 2 \\pi i n \\frac{t}{T}} B^w(t)\n",
    "$$\n",
    "\n",
    "We can now convert the windowed model to Fourier space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29090ec7",
   "metadata": {},
   "source": [
    "### Full-equation transformed\n",
    "\n",
    "Finally, the full equation with window function transformed to Fourier space is:\n",
    "\n",
    "$$\n",
    "    \\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\widehat{B}^{w}_n = -\\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\cos^2\\left(\\pi\\frac{q}{T}\\right) \\mathcal{F}\\big\\{[1 + \\epsilon\\cos(\\omega_d (t+q))]\\widetilde{f}^w\\big\\}_n + \\sigma B_{max} \\sqrt{\\tau} \\widehat{\\eta}^w_n\n",
    "$$\n",
    "\n",
    "To proceed with the inference, we have to isolate $\\widehat{\\eta}^w_n$ by writing it as a function of $\\widehat{B}^w_n$:\n",
    "\n",
    "$$\n",
    "    \\widehat{\\eta}^w_n = \\frac{\\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\widehat{B}^{w}_n + \\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\cos^2\\left(\\pi\\frac{q}{T}\\right) \\mathcal{F}\\big\\{[1 + \\epsilon\\cos(\\omega_d (t+q))]\\widetilde{f}^w\\big\\}_n}{\\sigma B_{max}\\sqrt{\\tau}}\n",
    "$$\n",
    "\n",
    "With or without windowing, the formal expression of the equation is the same.\n",
    "\n",
    "\n",
    "Without the external modulation ($\\epsilon=0$), $\\widehat{\\eta}^w_n$ is written as: \n",
    "\n",
    "$$\n",
    "    \\widehat{\\eta}^w_n = \\frac{\\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\widehat{B}^{w}_n + \\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\cos^2\\left(\\pi\\frac{q}{T}\\right) \\mathcal{F}[\\widetilde{f}^w]_n}{\\sigma B_{max}\\sqrt{\\tau}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "072b70b9",
   "metadata": {},
   "source": [
    "### SET THE CONFIGURATION FOR ALL THE SAMPLINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration\n",
    "\n",
    "WINDOW = True   #use window in the fourier transform\n",
    "one_parameter=True    #use one_parm=sigma*Bmax*sqrt(tau) instead of sigma\n",
    "cos = True           # use cos(q/T) correction in log_likelihood\n",
    "covariance = False  # use covariance in log_likelihood\n",
    "extended_box = False  # use the box function with both Bmax and Bmin\n",
    "Bmin=1                #fixed (not a parameter)\n",
    "jeffrey_prior = True     # use Jeffrey's prior for sigma or one_parameter\n",
    "\n",
    "n_max = 170         \n",
    "each_ = 3\n",
    "if covariance:\n",
    "    each=1\n",
    "else:\n",
    "    each=each_\n",
    "\n",
    "maximum=True   ## set maximum value for Bmax and q in the prior\n",
    "\n",
    "with_pool = False      #paralelize the sampling\n",
    "steps_emcee = 5000\n",
    "rep_emcee = 1             # how many repetitions of EMCEE\n",
    "walkers=50  \n",
    "burn=25 #burn in\n",
    "thining=1\n",
    "\n",
    "filepath = \"D:\\\\Users\\\\prafl\\\\Documents\\\\PoD\\\\LaboratoryOfComputationalPhysics_Y5\\\\project\\\\\"  ##path where SDDE.jl is and data will be saved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a3be829",
   "metadata": {},
   "source": [
    "Load the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3da2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_real= np.loadtxt('bfield_from_sunspots.dat', delimiter=',')\n",
    "t=np.arange(0,len(B_real))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a7bd3ec",
   "metadata": {},
   "source": [
    "## Likelihood function\n",
    "\n",
    "We now want to define the likelihood function for the transformed signal in $\\widehat{\\eta^w}$.\n",
    "\n",
    "The transformed noise $\\widehat{\\eta}_n$ is distributed following a normal distribution:\n",
    "\n",
    "$$\n",
    "    f(\\widehat{\\eta}_n|\\boldsymbol{\\theta}) \\propto \\exp\\left(-\\frac{1}{2} |\\widehat{\\eta}_n|^2\\right)\n",
    "$$\n",
    "\n",
    "Therefore, given $\\widehat{\\boldsymbol{\\eta}}=(...,\\widehat{\\eta}_{-1},\\widehat{\\eta}_{0},\\widehat{\\eta}_{1},...)$, the distribution of $\\boldsymbol{\\widehat{\\eta}}$ is given by the product\n",
    "\n",
    "$$\n",
    "    f(\\widehat{\\boldsymbol{\\eta}}|\\boldsymbol{\\theta}) = \\prod_n f(\\widehat{\\eta}_n) \\propto \\exp\\left(-\\frac{1}{2}\\sum_n|\\widehat{\\eta}_n|^2\\right) = \\exp\\left(-\\frac{1}{2}\\boldsymbol{\\widehat{\\eta}}^T\\boldsymbol{\\widehat{\\eta}}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "The likelihood function for $\\widehat{\\boldsymbol{B}}$ in Fourier space is obtained from the change of variables $\\widehat{\\boldsymbol{\\eta}} \\longrightarrow \\widehat{\\boldsymbol{B}}$:\n",
    "\n",
    "$$\n",
    "    \\mathcal{L} = f(\\widehat{\\boldsymbol{B}}|\\boldsymbol{\\theta}) = f(\\widehat{\\boldsymbol{\\eta}}|\\boldsymbol{\\theta})\\big|_{\\widehat{\\boldsymbol{\\eta}}=\\widehat{\\boldsymbol{\\eta}}(\\widehat{\\boldsymbol{B}})}\\cdot\\left\\lvert\\frac{d\\widehat{\\boldsymbol{\\eta}}}{d\\widehat{\\boldsymbol{B}}}\\right\\rvert\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "However, when we deal with a windowed signal, such as $B^w(t)$, correlations arise between different modes of the Fourier transform. Therefore, the probability distribution $f(\\boldsymbol{\\widehat{\\eta}^w}|\\boldsymbol{\\theta})$ is not a simple product of independent gaussian distributions anymore, and the covariance matrix $\\Sigma_{n,m} = \\langle\\widehat{\\eta}^w_n, \\widehat{\\eta}^w_m\\rangle$ must be included:\n",
    "\n",
    "$$\n",
    "        f(\\boldsymbol{\\widehat{\\eta}^w}|\\boldsymbol{\\theta}) \\propto \\exp\\left(-\\frac{1}{2}\\left(\\boldsymbol{\\widehat{\\eta}^w}\\right)^T\\Sigma^{-1}\\boldsymbol{\\widehat{\\eta}^w}\\right)\n",
    "$$\n",
    "\n",
    "However, we can ignore the covariance matrix by sampling every 3 nodes: this is how we will lighten the computations in our code. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94971b0f",
   "metadata": {},
   "source": [
    "Before computing the Jacobian, we should taking into account that, since we are working with the discrete signal $\\boldsymbol{B}=(B(t_0), B(t_1), ... , B(t_{N-1}))$, we will not have the integral as we have written ahead, but we will be using the Discrete Fourier Transform (DFT):\n",
    "\n",
    "$$\n",
    "    \\mathcal{F}[\\boldsymbol{B}]_n = \\widehat{B}_n =\\sum_{i=0}^{N-1} e^{-2\\pi i n\\frac{t_i}{T}}B(t_i)\n",
    "$$\n",
    "\n",
    "and its inverse:\n",
    "\n",
    "$$\n",
    "    \\mathcal{F}^{-1}[\\widehat{\\boldsymbol{B}}](t_i) = B(t_i) = \\frac{1}{N}\\sum_{n=0}^{N-1}e^{2\\pi i n \\frac{t_i}{T}} \\widehat{B}_n\n",
    "$$\n",
    "\n",
    "\n",
    "The Jacobian element $(m, n)$, setting $\\epsilon = 0$, is given by:\n",
    "\n",
    "$$\n",
    "J^w_{n,m} = \\frac{1}{\\sigma B_{max}\\sqrt{\\tau}}\\bigg[\\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\delta_{nm} + \\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\mathcal{F}\\big[\\widetilde{f}^w\\big]_n\\bigg] \n",
    "$$\n",
    "Therefore, we can write our sampling posterior for $\\epsilon = 0$, as:\n",
    " \n",
    "$$\n",
    "        f(\\widehat{B}^w|\\boldsymbol{\\theta})  \\propto |\\det J^{w}| \\exp\\bigg(-\\frac{1}{2\\sigma^2 B_{max}^2\\tau}\\sum_n \\bigg\\lvert\\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\widehat{B}^{w}_n \\, + \n",
    "          \\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\cos^2\\left(\\pi\\frac{q}{T}\\right) \\mathcal{F}\\big[\\widetilde{f}^w\\big]_n\\bigg\\rvert^2\\bigg) \n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2acae40",
   "metadata": {},
   "source": [
    "### BAYESIAN INFERENCE FUNCTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6be7c92",
   "metadata": {},
   "source": [
    "Return the log posterior function for the given configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3be347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_inference(t, B, p):\n",
    "    \n",
    "    n = np.arange(0, len(t))\n",
    "    n_list = n[0:n_max:each]\n",
    "    T=len(t)\n",
    "    # Define window\n",
    "    def w(t):\n",
    "        if WINDOW:\n",
    "            return np.cos(np.pi * (t / T - 0.5))**2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "    # Define box * B\n",
    "    def f_erf(B,Bmax): \n",
    "        if extended_box:\n",
    "            res = (B/4) * (1+erf(B**2-Bmin**2)) * (1-erf(B**2-Bmax**2))\n",
    "        else:\n",
    "            res = 0.5 * (1 - erf(B**2 - Bmax**2)) * B\n",
    "        return res\n",
    "\n",
    "\n",
    "    # Find B windowed and Fourier transformed\n",
    "    Bw = B * w(t) \n",
    "    Bw_hat_tot = fft(Bw)\n",
    "\n",
    "    # Find the derivative of the Fourier transorm of the f tilde\n",
    "    nm_t = np.multiply.outer(np.subtract.outer(n_list,n_list),t)\n",
    "    expo = np.exp(-2*np.pi*1j*nm_t/T)\n",
    "\n",
    "\n",
    "    # Select each 3 modes\n",
    "    Bw_hat = Bw_hat_tot[0:n_max:each]\n",
    "\n",
    "\n",
    "    # Variance \n",
    "    var_w =np.abs(fft(w(t)**2))\n",
    "\n",
    "\n",
    "    # Covariance matrix\n",
    "    cov=(np.diag([var_w[0]]*len(n_list))+np.diag([var_w[1]]*(len(n_list)-1),1)+np.diag([var_w[2]]*(len(n_list)-2),2)+np.diag([var_w[1]]*(len(n_list)-1),-1)+np.diag([var_w[2]]*(len(n_list)-2),-2))\n",
    "    inv_cov=np.linalg.inv(cov)\n",
    "    \n",
    "    if maximum:    \n",
    "        Bmax_max=max(B)\n",
    "        q_max=3*q\n",
    "    \n",
    "    else:\n",
    "        Bmax_max=np.inf\n",
    "        q_max=np.inf\n",
    "\n",
    "\n",
    "    if one_parameter:\n",
    "        # Define log_prior\n",
    "        def log_prior(theta):\n",
    "            q, N, one_param, Bmax, tau = theta\n",
    "            if (q      > 0     and\n",
    "                q      < q_max and\n",
    "                N      > 0    and\n",
    "                one_param  >0 and\n",
    "                Bmax   > 0 and \n",
    "                Bmax < Bmax_max and\n",
    "                tau    > 0):\n",
    "                if jeffrey_prior:\n",
    "                    return -0.5*np.log(one_param)   \n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return -np.inf\n",
    "\n",
    "\n",
    "        # Define log_likelihood\n",
    "        def log_likelihood(theta):\n",
    "            q, N, one_param, Bmax, tau = theta\n",
    "\n",
    "            koef = (2 * np.pi * 1j * n_list * tau /T + 1)\n",
    "\n",
    "            f = f_erf(B,Bmax)\n",
    "            f_hat = fft(f*w(t))\n",
    "            f_hat = f_hat[0:n_max:each]\n",
    "\n",
    "            if extended_box:\n",
    "                func = 0.25*(1-erf(B**2 - Bmax**2))*(1+erf(B**2 - Bmin**2)) - (B**2/np.sqrt(np.pi))*(1+erf(B**2 - Bmin**2))*np.exp(-(B**2 - Bmax**2)**2) + (B**2/np.sqrt(np.pi))*(1-erf(B**2 - Bmax**2))*np.exp(-(B**2 - Bmin**2)**2)    \n",
    "            else:\n",
    "                func = -(2 * B**2 / np.sqrt(np.pi)) * np.exp(-(B**2 - Bmax**2)**2) - 0.5 * erf((B**2 - Bmax**2)) + 0.5  #derivative of ftilde\n",
    "            dFf_dBhat = expo @ func / len(t)\n",
    "            #dFf_dBhat = np.subtract.outer(fft(func)[0:n_max:each], fft(func)[0:n_max:each]) / len(t)\n",
    "\n",
    "\n",
    "            if covariance:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * f_hat)/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * dFf_dBhat)/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q /T) * f_hat)/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q /T) * dFf_dBhat)/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood = np.log(det_j)  -   0.5 * np.abs(np.conjugate(eta_hat)@inv_cov@eta_hat)\n",
    "\n",
    "            else:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * f_hat)/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * dFf_dBhat)/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q /T ) * f_hat)/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q /T) * dFf_dBhat)/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood =  - 0.5 * np.sum(np.abs(eta_hat)**2) / var_w[0] +np.log(det_j)\n",
    "                #print(log_likelihood)\n",
    "\n",
    "            return log_likelihood\n",
    "\n",
    "\n",
    "        # Define log_posterior   \n",
    "        def log_probability(theta):\n",
    "            q, N, sigma, Bmax, tau = theta\n",
    "            lp = log_prior(theta)\n",
    "            if not np.isfinite(lp):\n",
    "                return -np.inf\n",
    "            else:\n",
    "                return lp + log_likelihood(theta)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Define log_prior\n",
    "        # Define log_prior\n",
    "        def log_prior(theta):\n",
    "            q, N, one_param, Bmax, tau = theta\n",
    "            if (q      > 0     and\n",
    "                q      < q_max and\n",
    "                N      > 0    and\n",
    "                sigma  >0 and\n",
    "                Bmax   > 0 and \n",
    "                Bmax < Bmax_max and\n",
    "                tau    > 0):\n",
    "                if jeffrey_prior:\n",
    "                    return -0.5*np.log(one_param)   \n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return -np.inf\n",
    "\n",
    "        # Define log_likelihood\n",
    "        def log_likelihood(theta):\n",
    "            q, N, sigma, Bmax, tau = theta\n",
    "            coef = sigma * Bmax * np.sqrt(tau)\n",
    "            koef = (2 * np.pi * 1j * n_list * tau/T  + 1)\n",
    "\n",
    "            f = f_erf(B,Bmax)\n",
    "            f_hat = fft(f*w(t))\n",
    "            f_hat = f_hat[0:n_max:each]\n",
    "\n",
    "            if extended_box:\n",
    "                func = 0.25*(1-erf(B**2 - Bmax**2))*(1+erf(B**2 - Bmin**2)) - (B**2/np.sqrt(np.pi))*(1+erf(B**2 - Bmin**2))*np.exp(-(B**2 - Bmax**2)**2) + (B**2/np.sqrt(np.pi))*(1-erf(B**2 - Bmax**2))*np.exp(-(B**2 - Bmin**2)**2)    \n",
    "            else:\n",
    "                func = -(2 * B**2 / np.sqrt(np.pi)) * np.exp(-(B**2 - Bmax**2)**2) - 0.5 * erf((B**2 - Bmax**2)) + 0.5  #derivative of ftilde\n",
    "            dFf_dBhat = expo @ func / len(t)\n",
    "            #dFf_dBhat = np.subtract.outer(fft(func)[0:n_max:each], fft(func)[0:n_max:each]) / len(t)\n",
    "\n",
    "\n",
    "\n",
    "            if covariance:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * f_hat)/coef\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * dFf_dBhat)/coef\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q /T ) * f_hat)/coef\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q/T) * dFf_dBhat)/coef\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood = np.log(det_j)  -   0.5 * np.abs(np.conjugate(eta_hat)@inv_cov@eta_hat)\n",
    "\n",
    "            else:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * f_hat)\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * dFf_dBhat)\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * f_hat)\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * dFf_dBhat)\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood = np.log(det_j) + np.log(1/coef) * len(n_list) - (1/coef**2) * 1/var_w[0] * 0.5 * np.sum(np.abs(eta_hat)**2)\n",
    "\n",
    "            return log_likelihood\n",
    "\n",
    "\n",
    "        # Define log_posterior   \n",
    "        def log_probability(theta):\n",
    "            q, N, sigma, Bmax, tau = theta\n",
    "            lp = log_prior(theta)\n",
    "            if not np.isfinite(lp):\n",
    "                return -np.inf\n",
    "            else:\n",
    "                return lp + log_likelihood(theta)\n",
    "            \n",
    "    return log_probability, Bw_hat,Bw,n_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9992d093",
   "metadata": {},
   "source": [
    "Return the minima of the log posterior using scipy minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minima(log_prob,p):\n",
    "    nll = lambda *args: -log_prob(*args)\n",
    "    initial = np.array(p) + 0.01*np.array(p) * np.random.randn(len(p))\n",
    "    soln = minimize(nll, initial, args=())\n",
    "    minima = soln.x\n",
    "    print('Minima',minima,'\\n','Starting parameters',p)\n",
    "    return(minima)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66336576",
   "metadata": {},
   "source": [
    "Plot:\n",
    "- Data\n",
    "- Windowed data\n",
    "- Fourier transform of the data (only the selected nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(t,B,Bw,n_list):\n",
    "    fig,(ax1, ax2) = plt.subplots(nrows=2,ncols=1,figsize=(10,8))\n",
    "    fig.tight_layout(pad=3)\n",
    "    ax1.plot(t,B,label='B')\n",
    "    ax1.plot(t,Bw,label='B windowed')\n",
    "    ax1.set_xlabel('Time [month]')\n",
    "    ax1.set_ylabel('B')\n",
    "    ax1.legend()\n",
    "   \n",
    "   \n",
    "    \n",
    "    ax2.plot(n_list,np.abs(Bw_hat),label='Fourier transform of B field')\n",
    "    ax2.set_ylabel(r'$\\mathcal{F}(B)$')\n",
    "    ax2.set_xlabel('Mode n')\n",
    "    ax2.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2933a361",
   "metadata": {},
   "source": [
    "Create data using the model for a given set of parameters (using julia for solving de SDDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(p):\n",
    "    q, N, sigma, Bmax, tau = p\n",
    "\n",
    "    julia_code = f\"\"\"\n",
    "    include(\"SDDE.jl\")\n",
    "\n",
    "    tau = {tau}\n",
    "    N = {N}\n",
    "    sigma = {sigma}\n",
    "    Bmax = {Bmax}\n",
    "    q = {q}\n",
    "    p = (q, N, sigma, Bmax, tau)\n",
    "\n",
    "    simulated_data(p)\n",
    "    \"\"\"\n",
    "\n",
    "    Main.eval(julia_code)\n",
    "\n",
    "    filename = f\"SunspotSimulatedData_tau{tau}_N{N}_sigma{sigma}_Bmax{Bmax}_q{q}.csv\"\n",
    "\n",
    "    data_simulated = np.loadtxt(filepath + filename, delimiter=',')\n",
    "    return(data_simulated)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74dc47db",
   "metadata": {},
   "source": [
    "Plot the generated and real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_and_simulated_data(data_simulated,p, compare_real):\n",
    "    q, N, sigma, Bmax, tau = p\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(data_simulated, label=\"Predicted data\")\n",
    "    if compare_real:\n",
    "        plt.plot(B_real, label=\"Real data\")\n",
    "        \n",
    "    plt.title(fr\"Plot: $\\tau$={round(tau,1)}, N={round(N,2)}, $\\sigma$={round(sigma,3)}, Bmax={round(Bmax,1)}, q={round(q,1)}\")\n",
    "    plt.xlabel('Time [month]')\n",
    "    plt.ylabel('B')\n",
    "    plt.legend()\n",
    "    #plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3ab6239",
   "metadata": {},
   "source": [
    "Create the Markov chain using emcee package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6581890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_emcee(log_prob,p):\n",
    "    if with_pool:    \n",
    "    #np.random.seed(42)\n",
    "        p_init = p\n",
    "        for i in range(rep_emcee):\n",
    "            pos = p_init + 1e-2*np.array(p)* np.random.randn(walkers, len(p))\n",
    "            initial = pos\n",
    "            nwalkers, ndim = initial.shape\n",
    "\n",
    "            with Pool() as pool:\n",
    "                sampler = emcee.EnsembleSampler(\n",
    "                    nwalkers, ndim, log_prob, args=(),pool=pool\n",
    "                )\n",
    "                sampler.run_mcmc(initial, steps_emcee, progress=True)\n",
    "                samples = sampler.get_chain()\n",
    "                p_init = [np.mean(samples[:,:,i]) for i in range(len(p))]\n",
    "\n",
    "    else:\n",
    "        np.random.seed(42)\n",
    "        p_init = p\n",
    "        for i in range(rep_emcee):\n",
    "            pos = p_init + 1e-2*np.array(p) * np.random.randn(walkers, len(p))\n",
    "            nwalkers, ndim = pos.shape\n",
    "\n",
    "            sampler = emcee.EnsembleSampler(\n",
    "                nwalkers, ndim, log_prob, args=()\n",
    "            )\n",
    "            sampler.run_mcmc(pos, steps_emcee, progress=True)\n",
    "            samples = sampler.get_chain()\n",
    "            p_init = [np.mean(samples[:,:,i]) for i in range(len(p))]\n",
    "    return(sampler,ndim)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "637ac276",
   "metadata": {},
   "source": [
    "Plot the Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chains(sampler,p,labels,ndim):\n",
    "    fig, axes = plt.subplots(len(p), figsize=(10, 7), sharex=True)\n",
    "    samples = sampler.get_chain()\n",
    "    \n",
    "    for i in range(ndim):\n",
    "        ax = axes[i]\n",
    "        ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "        ax.set_xlim(0, len(samples))\n",
    "        ax.set_ylabel(labels[i])\n",
    "        ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "    axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76b50dfe",
   "metadata": {},
   "source": [
    "Plot the parameters distributions of the Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(sampler,p,burn,compare):\n",
    "    #tau_= sampler.get_autocorr_time()\n",
    "    flat_samples = sampler.get_chain(discard=burn, thin=thining, flat=True)\n",
    "    if compare:\n",
    "        fig = corner.corner(\n",
    "        flat_samples, labels=labels, truths=p\n",
    "        );\n",
    "    else:\n",
    "        fig = corner.corner(\n",
    "        flat_samples, labels=labels\n",
    "        );\n",
    "    #print('Autocorrelation time=',mean(tau_))\n",
    "    return(flat_samples)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94ee8718",
   "metadata": {},
   "source": [
    "Display and obtain the results for the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596bdb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(flat_samples,ndim):\n",
    "    results=np.zeros(ndim)\n",
    "    for i in range(ndim):\n",
    "        mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "        qq = np.diff(mcmc)\n",
    "        txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "        txt = txt.format(mcmc[1], qq[0], qq[1], labels[i])\n",
    "        display(Math(txt))\n",
    "        results[i]=mcmc[1]\n",
    "    return(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18e36b78",
   "metadata": {},
   "source": [
    "Plot the marginalized log probabilities setting the parameters to the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log_prob(results,label):\n",
    "    fig, axes = plt.subplots(len(label),figsize=(10, 20))\n",
    "    fig.tight_layout(pad=3)\n",
    "    for i in range(len(label)):\n",
    "        ax=axes[i]\n",
    "        x=np.linspace(results[i]*(0.8),results[i]*(1.2),200)\n",
    "        log_list=np.zeros(len(x))\n",
    "        results_i=np.copy(results)\n",
    "        \n",
    "        for j in range(len(x)):\n",
    "            results_i[i]=x[j]\n",
    "            log_list[j]=-log_prob(results_i)\n",
    "            \n",
    "        ax.plot(x,log_list)\n",
    "        ax.set_title(label[i])\n",
    "        ax.set_ylabel('log Posterior')\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b146ebbd",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec33b3fb",
   "metadata": {},
   "source": [
    "## WITHOUT TIDAL FORCING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97fc2e8a",
   "metadata": {},
   "source": [
    "We will start without taking into account the tidal forcing, setting $\\epsilon$ to 0.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d52d7bf",
   "metadata": {},
   "source": [
    "### ARTIFICIAL DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f196ed8",
   "metadata": {},
   "source": [
    "First we generate data solving the SDDE of the model and infere its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 30\n",
    "N = 10\n",
    "one_param= 20\n",
    "Bmax = 10.0 \n",
    "tau = 45\n",
    "sigma=one_param/Bmax/np.sqrt(tau)\n",
    "\n",
    "\n",
    "if one_parameter:\n",
    "    sigma=round(one_param/Bmax/np.sqrt(tau),3)\n",
    "    p = [q, N, one_param, Bmax, tau]\n",
    "    labels = [\"q\", \"N\", \"One parameter\",\"Bmax\",r\"$\\tau$\"]\n",
    "else:\n",
    "    p = [q, N, sigma, Bmax, tau]\n",
    "    labels = [\"q\", \"N\", r\"\\$sigma$\",\"Bmax\",r\"$\\tau$\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = [q, N, sigma, Bmax, tau]\n",
    "B_generated=generate_data(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all results\n",
    "log_prob, Bw_hat,Bw,n_list = bayesian_inference(t, B_generated, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(t,B_generated,Bw,n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90701b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima=find_minima(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebf79f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler,ndim=sampler_emcee(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b112d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_chains(sampler,p,labels,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2c8f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_samples=plot_distributions(sampler,p,burn,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48541e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=show_results(flat_samples,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = np.copy(results)\n",
    "results_[2]=results[2]/results_[3]/np.sqrt(results_[4])\n",
    "B_generated_predicted=generate_data(results_)\n",
    "plot_real_and_simulated_data(B_generated_predicted,results_,False)\n",
    "\n",
    "plt.plot(B_generated,label='Artificial data')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_prob(results,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9979b1cd",
   "metadata": {},
   "source": [
    "### REAL DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f81687b",
   "metadata": {},
   "source": [
    "Now we will infere the parameters for the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 105\n",
    "N = 1.2\n",
    "one_param= 20\n",
    "Bmax = 15\n",
    "tau = 18\n",
    "sigma=one_param/Bmax/np.sqrt(tau)\n",
    "\n",
    "\n",
    "if one_parameter:\n",
    "    sigma=round(one_param/Bmax/np.sqrt(tau),3)\n",
    "    p = [q, N, one_param, Bmax, tau]\n",
    "    labels = [\"q\", \"N\", \"One parameter\",\"Bmax\",\"r$\\tau$\"]\n",
    "else:\n",
    "    p = [q, N, sigma, Bmax, tau]\n",
    "    labels = [\"q\", \"N\", r\"$\\sigma$\",\"Bmax\",\"r$\\tau$\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358db200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all results\n",
    "log_prob, Bw_hat,Bw,n_list = bayesian_inference(t, B_real, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(t,B_real,Bw,n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima=find_minima(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25d3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler,ndim=sampler_emcee(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07177896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_chains(sampler,p,labels,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c0a0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_samples=plot_distributions(sampler,p,burn,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=show_results(flat_samples,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c57f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = np.copy(results)\n",
    "results_[2]=results_[2]/results_[3]/np.sqrt(results_[4])\n",
    "\n",
    "B_real_predicted=generate_data(results_)\n",
    "plot_real_and_simulated_data(B_real_predicted,results_,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66f9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_prob(results,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3311f05c",
   "metadata": {},
   "source": [
    "## WITH TIDAL FORCING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f926ba80",
   "metadata": {},
   "source": [
    "In a noiseless system that exhibits multiple stable equilibria, it would not be possible to switch between minima, without an external drive that enables to overcome the potential barrier between them. \n",
    "In a stochastic system, however, random fluctuations due to noise can occasionally overcome the potential barrier and enable the system to switch between different stable states.\n",
    "\n",
    "To further amplify the signal to noise ratio in such a system, an external modulation can be introduced, which helps lower—periodically—the potential barrier.\n",
    "Random noise will then boost the frequency of mode-switching, aided by the external modulation. \n",
    "\n",
    "This phenomenon is called _stochastic resonance_. \n",
    "In our model equation, the tidal forcing $\\epsilon\\cos(\\omega_d t)$, due to the planets of the Solar System, represents a weak periodic modulation. \n",
    "This modulation greatly increases the probability of mode-switching due to the additive white noise. \n",
    "In fact, it enables the system to jump frequently between two coexisting stable modes of oscillation: the _weak mode_ is thought to be behind the phenomenon known as Grand Minima, while the _strong mode_ is responsible for the 11-year solar cycle.\n",
    "\n",
    "Given $\\epsilon \\neq 0$, the sampling posterior is:\n",
    "\n",
    "$$\n",
    "f(\\widehat{B}^w|\\boldsymbol{\\theta}) \\propto \n",
    "|\\det J^{w}| \\exp\\bigg(-\\frac{1}{2\\sigma^2 B_{max}^2\\tau}\\sum_n \\bigg\\lvert\\left(\\frac{2 \\pi i n\\tau}{T} + 1 \\right)^2 \\widehat{B}^{w}_n + \\mathcal{N} e^{-2 \\pi i n \\frac{q}{T}} \\cos^2\\left(\\pi\\frac{q}{T}\\right) \\mathcal{F}\\big\\{[1 + \\epsilon\\cos(\\omega_d (t+q))]\\widetilde{f}^w\\big\\}_n\\bigg\\rvert^2\\bigg) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7618a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_inference_tidal(t, B, p):\n",
    "    \n",
    "    n = np.arange(0, len(t))\n",
    "    n_list = n[0:n_max:each]\n",
    "    T=len(t)\n",
    "    # Define window\n",
    "    def w(t):\n",
    "        if WINDOW:\n",
    "            return np.cos(np.pi * (t / T - 0.5))**2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "\n",
    "    # Define box * B\n",
    "    def f_erf(B,Bmax): \n",
    "        if extended_box:\n",
    "            res = (B/4) * (1+erf(B**2-Bmin**2)) * (1-erf(B**2-Bmax**2))\n",
    "        else:\n",
    "            res = 0.5 * (1 - erf(B**2 - Bmax**2)) * B\n",
    "        return res\n",
    "\n",
    "\n",
    "    # Find B windowed and Fourier transformed\n",
    "    Bw = B * w(t) \n",
    "    Bw_hat_tot = fft(Bw)\n",
    "\n",
    "    # Find the derivative of the Fourier transorm of the f tilde\n",
    "    nm_t = np.multiply.outer(np.subtract.outer(n_list,n_list),t)\n",
    "    expo = np.exp(-2*np.pi*1j*nm_t/T)\n",
    "\n",
    "\n",
    "    # Select each 3 modes\n",
    "    Bw_hat = Bw_hat_tot[0:n_max:each]\n",
    "\n",
    "\n",
    "    # Variance \n",
    "    var_w =np.abs(fft(w(t)**2))\n",
    "\n",
    "\n",
    "    # Covariance matrix\n",
    "    cov=(np.diag([var_w[0]]*len(n_list))+np.diag([var_w[1]]*(len(n_list)-1),1)+np.diag([var_w[2]]*(len(n_list)-2),2)+np.diag([var_w[1]]*(len(n_list)-1),-1)+np.diag([var_w[2]]*(len(n_list)-2),-2))\n",
    "    inv_cov=np.linalg.inv(cov)\n",
    "    \n",
    "    if maximum:    \n",
    "        Bmax_max=max(B)\n",
    "        q_max=3*q\n",
    "    \n",
    "    else:\n",
    "        Bmax_max=np.inf\n",
    "        q_max=np.inf\n",
    "\n",
    "\n",
    "    if one_parameter:\n",
    "        # Define log_prior\n",
    "        def log_prior(theta):\n",
    "            q, N, one_param, Bmax, tau, epsilon, wd = theta\n",
    "            if (q      > 0     and\n",
    "                q      < q_max and\n",
    "                N      > 0    and\n",
    "                one_param  >0 and\n",
    "                Bmax   > 0 and \n",
    "                Bmax < Bmax_max and\n",
    "                tau    > 0 and\n",
    "                epsilon > 0 and\n",
    "                wd > 0):\n",
    "                if jeffrey_prior:\n",
    "                    return -0.5*np.log(one_param)   \n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                return -np.inf\n",
    "\n",
    "\n",
    "        # Define log_likelihood\n",
    "        def log_likelihood(theta):\n",
    "            q, N, one_param, Bmax, tau, epsilon, wd = theta\n",
    "\n",
    "            koef = (2 * np.pi * 1j * n_list * tau /T + 1)\n",
    "\n",
    "            f = f_erf(B,Bmax)\n",
    "            f_hat = fft(f*w(t))\n",
    "            f_hat = f_hat[0:n_max:each]\n",
    "            \n",
    "            f_eps = f_erf(B,Bmax) * np.cos(wd*(t+q))\n",
    "            f_eps_hat = fft(f_eps * w(t))\n",
    "            f_eps_hat = f_eps_hat[0:n_max:each]\n",
    "\n",
    "            if extended_box:\n",
    "                func = 0.25*(1-erf(B**2 - Bmax**2))*(1+erf(B**2 - Bmin**2)) - (B**2/np.sqrt(np.pi))*(1+erf(B**2 - Bmin**2))*np.exp(-(B**2 - Bmax**2)**2) + (B**2/np.sqrt(np.pi))*(1-erf(B**2 - Bmax**2))*np.exp(-(B**2 - Bmin**2)**2)    \n",
    "            else:\n",
    "                func = -(2 * B**2 / np.sqrt(np.pi)) * np.exp(-(B**2 - Bmax**2)**2) - 0.5 * erf((B**2 - Bmax**2)) + 0.5  #derivative of ftilde\n",
    "            dFf_dBhat = expo @ func / len(t)\n",
    "            dFf_dBhat_eps = expo @ (func * np.cos(wd*(t+q))) / len(t)\n",
    "\n",
    "            if covariance:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * (f_hat + epsilon * f_eps_hat))/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * (dFf_dBhat + epsilon * dFf_dBhat_eps))/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * (f_hat + epsilon * f_eps_hat))/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * (dFf_dBhat + epsilon * dFf_dBhat_eps))/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood = np.log(det_j)  -   0.5 * np.abs(np.conjugate(eta_hat)@inv_cov@eta_hat)\n",
    "\n",
    "            else:\n",
    "                if cos:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * (f_hat + epsilon * f_eps_hat))/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * np.cos(np.pi * q / T)**2 * (dFf_dBhat + epsilon * dFf_dBhat_eps))/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "                else:\n",
    "                    eta_hat = (koef**2 * Bw_hat + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * (f_hat + epsilon * f_eps_hat))/one_param\n",
    "                    jacobian = (np.diag(koef**2) + N * np.exp(-2 * np.pi * 1j * n_list * q / T) * (dFf_dBhat + epsilon * dFf_dBhat_eps))/one_param\n",
    "                    det_j = np.abs(det(jacobian))\n",
    "\n",
    "                log_likelihood =  - 0.5 * np.sum(np.abs(eta_hat)**2) / var_w[0] +np.log(det_j)\n",
    "                #print(log_likelihood)\n",
    "\n",
    "            return log_likelihood\n",
    "\n",
    "\n",
    "        # Define log_posterior   \n",
    "        def log_probability(theta):\n",
    "            q, N, sigma, Bmax, tau, epsilon, wd = theta\n",
    "            lp = log_prior(theta)\n",
    "            if not np.isfinite(lp):\n",
    "                return -np.inf\n",
    "            else:\n",
    "                return lp + log_likelihood(theta)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('ONLY ONE PARAMETER!')\n",
    "            \n",
    "    return log_probability, Bw_hat,Bw,n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_tidal(p):\n",
    "    q, N, sigma, Bmax, tau, epsilon, wd = p\n",
    "    \n",
    "    julia_code = f\"\"\"\n",
    "    include(\"SDDE_epsilon.jl\")\n",
    "    \n",
    "    q={q}\n",
    "    N = {N}\n",
    "    sigma = {sigma}\n",
    "    Bmax = {Bmax}\n",
    "    tau = {tau}\n",
    "    epsilon = {epsilon}\n",
    "    wd = {wd}\n",
    "    p = (q, N, sigma, Bmax, tau, epsilon, wd)\n",
    "\n",
    "    simulated_data(p)\n",
    "    \"\"\"\n",
    "\n",
    "    Main.eval(julia_code)\n",
    "\n",
    "    filename = f\"SunspotSimulatedData_q{q}_N{N}_sigma{sigma}_Bmax{Bmax}_tau{tau}_epsilon{epsilon}_wd{wd}.csv\"\n",
    "    \n",
    "    data_simulated = np.loadtxt(filepath + filename, delimiter=',')\n",
    "    \n",
    "    return(data_simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36519b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_and_simulated_data_tidal(data_simulated, p, compare_real):\n",
    "    q, N, sigma, Bmax, tau, epsilon, wd = p\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(data_simulated, label=\"Predicted data\")\n",
    "    if compare_real:\n",
    "        plt.plot(B_real, label=\"Real data\")\n",
    "    \n",
    "    plt.title(fr\"Plot: $\\tau$={round(tau,1)}, N={round(N,2)}, $\\sigma$={round(sigma,3)}, Bmax={round(Bmax,1)}, q={round(q,1)}, epsilon={round(epsilon,3)}, wd={round(wd,4)}\")\n",
    "    plt.xlabel('Time [month]')\n",
    "    plt.ylabel('B')\n",
    "    plt.legend()\n",
    "   # plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbd6e2bf",
   "metadata": {},
   "source": [
    "### ARTIFICIAL DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76c88d35",
   "metadata": {},
   "source": [
    "As before, we start with artificial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLY VALID FOR ONE PARAMETER\n",
    "one_parameter=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2466494",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 30\n",
    "N = 10\n",
    "one_param= 20\n",
    "Bmax = 10.0 \n",
    "tau = 45\n",
    "sigma=one_param/Bmax/np.sqrt(tau)\n",
    "epsilon=0.5\n",
    "wd=0.02\n",
    "\n",
    "\n",
    "\n",
    "sigma=round(one_param/Bmax/np.sqrt(tau),3)\n",
    "p = [q, N, one_param, Bmax, tau,epsilon,wd]\n",
    "labels = [\"q\", \"N\", \"One parameter\",\"Bmax\",r\"\\$tau$\",r'\\$epsilon$',r'\\$omega$d']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1263f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = [q, N, sigma, Bmax, tau,epsilon,wd]\n",
    "B_generated=generate_data_tidal(p_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bfdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all results\n",
    "log_prob, Bw_hat,Bw,n_list = bayesian_inference_tidal(t, B_generated, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8838e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(t,B_generated,Bw,n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima=find_minima(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bfde85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler,ndim=sampler_emcee(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ba14c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_chains(sampler,p,labels,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5cff5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_samples=plot_distributions(sampler,p,burn,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25753ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=show_results(flat_samples,ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93e72cb3",
   "metadata": {},
   "source": [
    "The mariginal parameter posterior distributions are well defined, except for Bmax which presents 3 main peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = np.copy(results)\n",
    "results_[2]=results[2]/results_[3]/np.sqrt(results_[4])\n",
    "B_generated_predicted=generate_data_tidal(results_)\n",
    "plot_real_and_simulated_data_tidal(B_generated_predicted,results_,False)\n",
    "\n",
    "plt.plot(B_generated,label='Artificial data')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fcecfc3",
   "metadata": {},
   "source": [
    "The predicted datas do not follow the original ones, actually the trend is quite the same, but the amplitude, delay and noise are not correctly represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc42bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_prob(results,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c14ecf51",
   "metadata": {},
   "source": [
    "### REAL DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b3e75fb",
   "metadata": {},
   "source": [
    "We finally proceed with the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 105\n",
    "N = 1.14\n",
    "one_param= 26.7\n",
    "Bmax = 15.3\n",
    "tau = 12.59\n",
    "epsilon = 4.76\n",
    "wd = 22.72\n",
    "\n",
    "sigma=round(one_param/Bmax/np.sqrt(tau),3)\n",
    "p = [q, N, one_param, Bmax, tau,epsilon,wd]\n",
    "labels = [\"q\", \"N\", \"One parameter\",\"Bmax\",\"tau\",'epsilon','wd']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cda7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all results\n",
    "log_prob, Bw_hat,Bw,n_list = bayesian_inference_tidal(t, B_real, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0401ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima=find_minima(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787af811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler,ndim=sampler_emcee(log_prob,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f00d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_chains(sampler,p,labels,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefd72a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flat_samples=plot_distributions(sampler,p,burn,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa09326c",
   "metadata": {},
   "source": [
    "The marginal paramater distribution are not well found. The contour plots are not defined. The EMCEE sampler is not able to find a stable values for the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=show_results(flat_samples,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = np.copy(results)\n",
    "results_[2]=results_[2]/results_[3]/np.sqrt(results_[4])\n",
    "\n",
    "B_real_predicted=generate_data_tidal(results_)\n",
    "plot_real_and_simulated_data_tidal(B_real_predicted,results_,True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6e019a4",
   "metadata": {},
   "source": [
    "Beside the fact that the parameter posterior marginal distributions do not lead us to stable parameter values, the predicted data are quite similar to the real ones, except for a shift in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4db158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_prob(results,labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb3b15fe",
   "metadata": {},
   "source": [
    "Now we want to make a prediction on future data. \n",
    "\n",
    "Given the orignal data, we add in continuity the data whose parameters are sampled by the EMCEE sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4628bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_predict(p):\n",
    "    q, N, sigma, Bmax, tau, epsilon, wd = p\n",
    "    \n",
    "    julia_code = f\"\"\"\n",
    "    include(\"Predict.jl\")\n",
    "    \n",
    "    q={q}\n",
    "    N = {N}\n",
    "    sigma = {sigma}\n",
    "    Bmax = {Bmax}\n",
    "    tau = {tau}\n",
    "    epsilon = {epsilon}\n",
    "    wd = {wd}\n",
    "    p = (q, N, sigma, Bmax, tau, epsilon, wd)\n",
    "\n",
    "    simulated_data(p)\n",
    "    \"\"\"\n",
    "\n",
    "    Main.eval(julia_code)\n",
    "\n",
    "    filename = f\"SunspotSimulatedData_q{q}_N{N}_sigma{sigma}_Bmax{Bmax}_tau{tau}_epsilon{epsilon}_wd{wd}.csv\"\n",
    "    \n",
    "    data_simulated = np.loadtxt(filepath + filename, delimiter=',')\n",
    "    \n",
    "    return(data_simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=generate_data_predict(results_)\n",
    "\n",
    "t_predicted=np.arange(len(B_real),len(B_real)+1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(t,B_real,c='red',marker='o',s=0.6,label='Past B field')\n",
    "plt.scatter(t_predicted,prediction[0:1000],c='orange',marker='o',s=0.6,label='Future B field')\n",
    "plt.axvline(x=len(B_real),linestyle='-',alpha=0.25,c='black')\n",
    "plt.xlabel('Time [month]')\n",
    "plt.ylabel('B')\n",
    "lgnd=plt.legend()\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93298810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d05f466782cbb03077cc3bdda8f13174421d901c269bb88e7af63bb2c0adcb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
